Epoch 1
Training loss: 0.8088041960392255
Val Loss =  0.8540750825801469
Val F1 =  0.6390034373958796
Accuracy Score =  0.65529
              precision    recall  f1-score   support

           1       0.68      0.67      0.67     10498
           2       0.41      0.28      0.33      6723
           3       0.43      0.34      0.38     10645
           4       0.43      0.37      0.40     19751
           5       0.76      0.87      0.82     52383

    accuracy                           0.66    100000
   macro avg       0.54      0.51      0.52    100000
weighted avg       0.63      0.66      0.64    100000


Epoch 2
Training loss: 0.800119286687879
Val Loss =  0.8264468269579855
Val F1 =  0.6479266062019684
Accuracy Score =  0.66225
              precision    recall  f1-score   support

           1       0.68      0.70      0.69     10498
           2       0.43      0.28      0.34      6723
           3       0.43      0.36      0.39     10645
           4       0.44      0.38      0.41     19751
           5       0.78      0.87      0.82     52383

    accuracy                           0.66    100000
   macro avg       0.55      0.52      0.53    100000
weighted avg       0.64      0.66      0.65    100000


Epoch 3
Training loss: 0.7587026868656669
Val Loss =  0.819168968121414
Val F1 =  0.6525518019740609
Accuracy Score =  0.67029
              precision    recall  f1-score   support

           1       0.70      0.69      0.70     10498
           2       0.44      0.30      0.35      6723
           3       0.47      0.35      0.40     10645
           4       0.46      0.38      0.42     19751
           5       0.77      0.89      0.82     52383

    accuracy                           0.67    100000
   macro avg       0.57      0.52      0.54    100000
weighted avg       0.64      0.67      0.65    100000


Epoch 4
Training loss: 0.7219734551886755
Val Loss =  0.8221233311821433
Val F1 =  0.6595592617829635
Accuracy Score =  0.67279
              precision    recall  f1-score   support

           1       0.70      0.69      0.70     10498
           2       0.43      0.33      0.38      6723
           3       0.46      0.38      0.41     10645
           4       0.46      0.39      0.42     19751
           5       0.78      0.88      0.83     52383

    accuracy                           0.67    100000
   macro avg       0.57      0.54      0.55    100000
weighted avg       0.65      0.67      0.66    100000


Epoch 5
Training loss: 0.6883152668779657
Val Loss =  0.8313861763690744
Val F1 =  0.6637248469739252
Accuracy Score =  0.67458
              precision    recall  f1-score   support

           1       0.67      0.74      0.70     10498
           2       0.44      0.32      0.37      6723
           3       0.46      0.39      0.42     10645
           4       0.47      0.42      0.44     19751
           5       0.80      0.86      0.83     52383

    accuracy                           0.67    100000
   macro avg       0.56      0.55      0.55    100000
weighted avg       0.66      0.67      0.66    100000


Epoch 6
Training loss: 0.6596527895291341
Val Loss =  0.8430208005868566
Val F1 =  0.6636839238829984
Accuracy Score =  0.67989
              precision    recall  f1-score   support

           1       0.71      0.71      0.71     10498
           2       0.46      0.34      0.39      6723
           3       0.47      0.40      0.43     10645
           4       0.48      0.38      0.42     19751
           5       0.77      0.89      0.83     52383

    accuracy                           0.68    100000
   macro avg       0.58      0.54      0.56    100000
weighted avg       0.66      0.68      0.66    100000


Epoch 7
Training loss: 0.6348055052169987
Val Loss =  0.8421879723248884
Val F1 =  0.6693858446314096
Accuracy Score =  0.6811
              precision    recall  f1-score   support

           1       0.70      0.72      0.71     10498
           2       0.44      0.37      0.40      6723
           3       0.47      0.40      0.43     10645
           4       0.48      0.40      0.44     19751
           5       0.79      0.87      0.83     52383

    accuracy                           0.68    100000
   macro avg       0.58      0.55      0.56    100000
weighted avg       0.66      0.68      0.67    100000


Epoch 8
Training loss: 0.6135045208956901
Val Loss =  0.858849104103225
Val F1 =  0.6693437531624289
Accuracy Score =  0.68358
              precision    recall  f1-score   support

           1       0.70      0.72      0.71     10498
           2       0.44      0.37      0.40      6723
           3       0.48      0.40      0.44     10645
           4       0.49      0.38      0.43     19751
           5       0.78      0.89      0.83     52383

    accuracy                           0.68    100000
   macro avg       0.58      0.55      0.56    100000
weighted avg       0.66      0.68      0.67    100000


Epoch 9
Training loss: 0.5991961820836412
Val Loss =  0.861747809230824
Val F1 =  0.6715589100998145
Accuracy Score =  0.68363
              precision    recall  f1-score   support

           1       0.71      0.71      0.71     10498
           2       0.46      0.35      0.40      6723
           3       0.48      0.40      0.44     10645
           4       0.48      0.41      0.45     19751
           5       0.79      0.88      0.83     52383

    accuracy                           0.68    100000
   macro avg       0.58      0.55      0.56    100000
weighted avg       0.66      0.68      0.67    100000


Epoch 10
Training loss: 0.5886316671824501
Val Loss =  0.8644046637103381
Val F1 =  0.6735335792307972
Accuracy Score =  0.68324
              precision    recall  f1-score   support

           1       0.70      0.72      0.71     10498
           2       0.45      0.36      0.40      6723
           3       0.48      0.41      0.44     10645
           4       0.48      0.43      0.45     19751
           5       0.80      0.87      0.83     52383

    accuracy                           0.68    100000
   macro avg       0.58      0.56      0.57    100000
weighted avg       0.67      0.68      0.67    100000
