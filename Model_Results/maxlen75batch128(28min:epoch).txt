Epoch 1
Training loss: 0.8776881454849244
Val Loss =  0.8005488599505266
Val F1 =  0.6510569468250361
Accuracy Score =  0.66944
              precision    recall  f1-score   support

           1       0.66      0.76      0.71     10581
           2       0.44      0.26      0.33      6811
           3       0.43      0.40      0.42     10597
           4       0.46      0.34      0.39     19398
           5       0.78      0.88      0.82     52613

    accuracy                           0.67    100000
   macro avg       0.55      0.53      0.53    100000
weighted avg       0.64      0.67      0.65    100000


Epoch 2
Training loss: 0.7759512872695923
Val Loss =  0.7774294814490297
Val F1 =  0.6701900225531773
Accuracy Score =  0.6799
              precision    recall  f1-score   support

           1       0.69      0.75      0.72     10581
           2       0.46      0.31      0.37      6811
           3       0.46      0.38      0.42     10597
           4       0.46      0.44      0.45     19398
           5       0.80      0.86      0.83     52613

    accuracy                           0.68    100000
   macro avg       0.57      0.55      0.56    100000
weighted avg       0.66      0.68      0.67    100000


Epoch 3
Training loss: 0.7206879073143005
Val Loss =  0.7620608814232185
Val F1 =  0.6758510058733483
Accuracy Score =  0.6909
              precision    recall  f1-score   support

           1       0.71      0.76      0.73     10581
           2       0.47      0.34      0.39      6811
           3       0.49      0.39      0.43     10597
           4       0.48      0.40      0.43     19398
           5       0.79      0.89      0.84     52613

    accuracy                           0.69    100000
   macro avg       0.59      0.55      0.57    100000
weighted avg       0.67      0.69      0.68    100000


Epoch 4
Training loss: 0.6724553448486328
Val Loss =  0.7640345461685639
Val F1 =  0.6820890469878285
Accuracy Score =  0.69543
              precision    recall  f1-score   support

           1       0.75      0.72      0.74     10581
           2       0.49      0.36      0.41      6811
           3       0.49      0.42      0.45     10597
           4       0.48      0.41      0.44     19398
           5       0.79      0.90      0.84     52613

    accuracy                           0.70    100000
   macro avg       0.60      0.56      0.58    100000
weighted avg       0.68      0.70      0.68    100000


Epoch 5
Training loss: 0.627793822927475
Val Loss =  0.7731322244838681
Val F1 =  0.6895241695548524
Accuracy Score =  0.70001
              precision    recall  f1-score   support

           1       0.73      0.75      0.74     10581
           2       0.48      0.39      0.43      6811
           3       0.50      0.43      0.46     10597
           4       0.49      0.43      0.46     19398
           5       0.81      0.89      0.84     52613

    accuracy                           0.70    100000
   macro avg       0.60      0.58      0.59    100000
weighted avg       0.68      0.70      0.69    100000


Epoch 6
Training loss: 0.5897041734313965
Val Loss =  0.7896713841601711
Val F1 =  0.6935156822445232
Accuracy Score =  0.70277
              precision    recall  f1-score   support

           1       0.76      0.73      0.74     10581
           2       0.48      0.41      0.44      6811
           3       0.51      0.42      0.46     10597
           4       0.50      0.45      0.47     19398
           5       0.81      0.89      0.84     52613

    accuracy                           0.70    100000
   macro avg       0.61      0.58      0.59    100000
weighted avg       0.69      0.70      0.69    100000



Epoch 7
Training loss: 0.5572806867694855
Val Loss =  0.8080470738813396
Val F1 =  0.6950187466145157
Accuracy Score =  0.70516
              precision    recall  f1-score   support

           1       0.75      0.74      0.75     10581
           2       0.51      0.37      0.43      6811
           3       0.51      0.45      0.48     10597
           4       0.50      0.44      0.47     19398
           5       0.81      0.89      0.85     52613

    accuracy                           0.71    100000
   macro avg       0.62      0.58      0.59    100000
weighted avg       0.69      0.71      0.70    100000


Epoch 8
Training loss: 0.5303017128562927
Val Loss =  0.821487497071476
Val F1 =  0.6980513343316762
Accuracy Score =  0.70675
              precision    recall  f1-score   support

           1       0.76      0.74      0.75     10581
           2       0.49      0.42      0.46      6811
           3       0.50      0.47      0.49     10597
           4       0.51      0.43      0.47     19398
           5       0.81      0.88      0.85     52613

    accuracy                           0.71    100000
   macro avg       0.62      0.59      0.60    100000
weighted avg       0.69      0.71      0.70    100000


Epoch 9
Training loss: 0.508531597108841
Val Loss =  0.8303848942146277
Val F1 =  0.6972845911438781
Accuracy Score =  0.7075
              precision    recall  f1-score   support

           1       0.75      0.75      0.75     10581
           2       0.50      0.42      0.46      6811
           3       0.52      0.44      0.48     10597
           4       0.51      0.44      0.47     19398
           5       0.81      0.89      0.85     52613

    accuracy                           0.71    100000
   macro avg       0.62      0.59      0.60    100000
weighted avg       0.69      0.71      0.70    100000


Epoch 10
Training loss: 0.49594518918037417
Val Loss =  0.8351277763505116
Val F1 =  0.7002467890723262
Accuracy Score =  0.70774
              precision    recall  f1-score   support

           1       0.76      0.75      0.75     10581
           2       0.50      0.43      0.46      6811
           3       0.51      0.46      0.49     10597
           4       0.51      0.46      0.48     19398
           5       0.81      0.88      0.85     52613

    accuracy                           0.71    100000
   macro avg       0.62      0.59      0.60    100000
weighted avg       0.70      0.71      0.70    100000